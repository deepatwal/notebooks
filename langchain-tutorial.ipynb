{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "import random\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.messages import (\n",
    "    SystemMessage,\n",
    "    AIMessage,\n",
    "    HumanMessage\n",
    ")\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import (\n",
    "    ChatMessagePromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runnable in Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable Sequence constructed using \"|\" operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 6, 8]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = RunnableLambda(lambda x: x + 1) | RunnableLambda(lambda x: x * 2)\n",
    "\n",
    "# sequence.invoke(1)\n",
    "sequence.batch([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable Parallel constructed using dict literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mul_2': 4, 'mul_4': 8}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = RunnableLambda(lambda x: x + 1) | {\n",
    "    \"mul_2\": RunnableLambda(lambda x: x * 2),\n",
    "    \"mul_4\": RunnableLambda(lambda x: x * 4)\n",
    "    }\n",
    "\n",
    "sequence.invoke(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable additional methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x: int) -> int:\n",
    "    return x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buggy_double(y: int) -> int:\n",
    "    if random.random() > 0.3:\n",
    "        print(\"this code failed and will probably be retired!\")\n",
    "        raise ValueError(\"Triggered buggy code\")\n",
    "    return y * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableLambda(add)\n",
       "| RunnableRetry(bound=RunnableLambda(buggy_double), wait_exponential_jitter=False, max_attempt_number=10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sequence = RunnableLambda(add) | RunnableLambda(buggy_double)\n",
    "\n",
    "sequence = RunnableLambda(add) | RunnableLambda(buggy_double).with_retry(stop_after_attempt=10, wait_exponential_jitter=False)\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'add_input', 'type': 'integer'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence.input_schema.schema()\n",
    "# sequence.invoke(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'buggy_double_output', 'type': 'integer'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence.output_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# langauge models in langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### llms: refers to pure text completion models\n",
    "\n",
    "-   invoking llms with a plain string will return the results as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3.1:8b\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(response): <class 'str'>\n",
      "Here are some ideas:\n",
      "\n",
      "1. **SockSavvy**: This name plays off the idea of being knowledgeable or \"savvy\" about socks, which could be appealing to customers.\n",
      "2. **ColorCrew**: This name emphasizes the fun, colorful aspect of your company's products and implies a team effort in creating them.\n",
      "3. **ToeTally Fun**: This name is playful and lighthearted, suggesting that your socks are not only colorful but also enjoyable to wear.\n",
      "4. **SoleMates Socks**: This name has a fun double meaning, referencing both the sole of a sock and the idea of finding a perfect match (either for yourself or as a gift).\n",
      "5. **Heelicious**: Similar to \"ToeTally Fun,\" this name is playful and emphasizes the delicious aspect of colorful socks.\n",
      "6. **StepUp Socks**: This name suggests that your company's products will help customers take their sock game to the next level.\n",
      "7. **SockItToMe**: This name has a fun, casual vibe and implies that your socks are so good, you'll want to \"sock it to me\" (i.e., try them out).\n",
      "8. **VibeSocks**: This name emphasizes the fun, energetic atmosphere of your company's products.\n",
      "9. **SockScene**: This name suggests that your company is at the center of a vibrant, exciting world of colorful socks.\n",
      "10. **SockItOut**: This name has a fun, playful vibe and implies that your company's products will help customers stand out from the crowd.\n",
      "\n",
      "I hope these ideas inspire you to find the perfect name for your company!\n"
     ]
    }
   ],
   "source": [
    "# response = llm.invoke(\"what would be a good company name for a company that makes colorful socks ?\")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product} ?\")\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({\"product\": \"colorful socks\"})\n",
    "\n",
    "print(f\"type(response): {type(response)}\")\n",
    "# print(f\"content: {response.content}\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chat model: tuned specifically for having conversations\n",
    "\n",
    "-   invoking chat models with a list of messages will return the results as a AIMessage list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_chat_model = ChatOllama(model=\"llama3.1:8b\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(response): <class 'langchain_core.messages.ai.AIMessage'>\n",
      "response: content='Here are some ideas for a company name that might fit the bill:\\n\\n1. **SoleMates**: A playful name that suggests the socks will become your best friends.\\n2. **ColorCrew**: This name emphasizes the fun, colorful aspect of the socks and implies a team or crew behind them.\\n3. **SockScene**: A catchy name that evokes the idea of a vibrant, dynamic scene - which is exactly what colorful socks can bring to an outfit!\\n4. **ToeTally Fun**: A whimsical name that conveys the playful spirit of the company and its products.\\n5. **HueHub**: This name highlights the variety of colors available in the socks and creates a sense of community or hub around them.\\n6. **StepUp Socks**: A motivational name that encourages customers to step up their style game with colorful, fun socks.\\n7. **SockSavvy**: This name positions the company as experts in all things sock-related - which can be appealing to customers looking for high-quality, stylish options.\\n8. **PatternPlay**: A creative name that emphasizes the playful aspect of colorful socks and suggests a sense of experimentation or exploration.\\n9. **SockStudio**: A simple, yet effective name that implies a focus on creativity and craftsmanship in the design and production of the socks.\\n10. **VibeSocks**: This name captures the energetic, lively vibe of colorful socks and creates a sense of excitement around the brand.\\n\\nWhich one do you like best?' response_metadata={'model': 'llama3.1:8b', 'created_at': '2024-07-24T15:30:56.292356457Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 9934397804, 'load_duration': 11162954, 'prompt_eval_count': 44, 'prompt_eval_duration': 90778000, 'eval_count': 302, 'eval_duration': 9657102000} id='run-94072e3c-fd73-4c8f-89a1-12259d2803a6-0'\n",
      "response.content: Here are some ideas for a company name that might fit the bill:\n",
      "\n",
      "1. **SoleMates**: A playful name that suggests the socks will become your best friends.\n",
      "2. **ColorCrew**: This name emphasizes the fun, colorful aspect of the socks and implies a team or crew behind them.\n",
      "3. **SockScene**: A catchy name that evokes the idea of a vibrant, dynamic scene - which is exactly what colorful socks can bring to an outfit!\n",
      "4. **ToeTally Fun**: A whimsical name that conveys the playful spirit of the company and its products.\n",
      "5. **HueHub**: This name highlights the variety of colors available in the socks and creates a sense of community or hub around them.\n",
      "6. **StepUp Socks**: A motivational name that encourages customers to step up their style game with colorful, fun socks.\n",
      "7. **SockSavvy**: This name positions the company as experts in all things sock-related - which can be appealing to customers looking for high-quality, stylish options.\n",
      "8. **PatternPlay**: A creative name that emphasizes the playful aspect of colorful socks and suggests a sense of experimentation or exploration.\n",
      "9. **SockStudio**: A simple, yet effective name that implies a focus on creativity and craftsmanship in the design and production of the socks.\n",
      "10. **VibeSocks**: This name captures the energetic, lively vibe of colorful socks and creates a sense of excitement around the brand.\n",
      "\n",
      "Which one do you like best?\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are an AI assistant\"),\n",
    "    HumanMessage(content=\"what would be a good company name for a company that makes colorful socks ?\")\n",
    "    ]\n",
    "\n",
    "response = ollama_chat_model.invoke(input=messages)\n",
    "\n",
    "print(f\"type(response): {type(response)}\")\n",
    "print(f\"response: {response}\")\n",
    "\n",
    "print(f\"response.content: {response.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(result): <class 'str'>\n",
      "result: What is a good name for a company that makes colorful socks ?\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product} ?\")\n",
    "result = prompt.format(product= \"colorful socks\")\n",
    "\n",
    "print(f\"type(result): {type(result)}\")\n",
    "print(f\"result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(result): <class 'langchain_core.prompt_values.ChatPromptValue'>\n",
      "result: messages=[SystemMessage(content='you are a helpful assistant that translates English to French.'), HumanMessage(content='I love programming.')]\n"
     ]
    }
   ],
   "source": [
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you are a helpful assistant that translates {input_language} to {output_language}.\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "\n",
    "# print(type(chat_prompt_template))\n",
    "# chat_prompt_template.format_messages(input_language=\"English\", output_language=\"French\", text=\"I love programming.\")\n",
    "\n",
    "result = chat_prompt_template.invoke({\"input_language\": \"English\", \"output_language\": \"French\", \"text\": \"I love programming.\"})\n",
    "\n",
    "print(f\"type(result): {type(result)}\")\n",
    "print(f\"result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# output parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'bye']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser = CommaSeparatedListOutputParser()\n",
    "output_parser.parse(\"hi, bye\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# composing with LCEL: lang chain expression language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red', 'blue', 'green', 'yellow', 'purple']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model = ChatOllama(model=\"llama3.1:8b\", temperature=0)\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "prompt = ChatPromptTemplate.from_template(\"Generate a list of 5 {text}.\\n\\n{format_instructions}\")\n",
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", \"you are a helpful assistant.\"),\n",
    "#     (\"human\", \"Generate a list of 5 {text}. \\n\\n {format_instructions}\")\n",
    "\n",
    "# ])\n",
    "\n",
    "prompt = prompt.partial(format_instructions=output_parser.get_format_instructions())\n",
    "\n",
    "chain = prompt | chat_model | output_parser\n",
    "\n",
    "chain.invoke({\"text\": \"colors\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompts Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String PromptTemplates\n",
    "-   used to create a template from a string prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = PromptTemplate.from_template(\"tell me a {adjective} joke about {content}.\")\n",
    "prompt_template.format(adjective=\"funny\", content=\"chickens\")\n",
    "# result = prompt_template.invoke({\"adjective\": \"sad\", \"content\": \"chickens\"})\n",
    "# print(type(result))\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Prompt Template\n",
    "-   The prompt to chat models/ is a list of chat messages.\n",
    "-   Each chat message is associated with content, and an additional parameter called role.\n",
    "-   For example, in the OpenAI Chat Completions API, a chat message can be associated with an AI assistant, a human or a system role.\n",
    "-   The ChatPromptTemplate.from_messages static method accepts a variety of message representations and is a convenient way to format input to chat models with exactly the messages you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(messages): <class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='you are a helpful AI bot. Your name is Jarvis'),\n",
       " HumanMessage(content='Hello, how are you doing?.'),\n",
       " AIMessage(content=\"I'm doing well, thanks!\"),\n",
       " HumanMessage(content='what is your name?')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"you are a helpful AI bot. Your name is {name}\"),\n",
    "        (\"human\", \"Hello, how are you doing?.\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"{user_input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_prompt_template.format_messages(name=\"Jarvis\", user_input=\"what is your name?\")\n",
    "# messages = chat_prompt_template.invoke({\"name\": \"Jarvis\", \"user_input\": \"what is your name?\"})\n",
    "\n",
    "print(f\"type(messages): {type(messages)}\")\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content=\"You are a helpful assistant that re-writes the user's text to sound it more upbeat\"), HumanMessage(content='what is your name?')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful assistant that re-writes the user's text to sound it more upbeat\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_prompt_template.invoke({\"text\": \"what is your name?\"})\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message Prompts\n",
    "- used where the chat model supports taking chat message with arbitrary role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_message_prompt_template = ChatMessagePromptTemplate.from_template(role=\"Jedi\", template=\"May the {subject} be with you\")\n",
    "chat_message_prompt_template.format(subject=\"force\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message Placeholder\n",
    "- gives full control of what messages to be rendered during formatting.\n",
    "- used when uncertain of what role should be used and wish to insert a list of messages during formatting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message_template = HumanMessagePromptTemplate.from_template(\"Summarize our conversation so far in {word_count} words.\")\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"conversation\"), \n",
    "    human_message_template\n",
    "    ])\n",
    "\n",
    "human_message = HumanMessage(content=\"What is the best way to learn programming?\")\n",
    "ai_message = AIMessage(content=\"\"\"\n",
    "1. Choose a programming language: Decide on a programming language that you want to learn.\n",
    "\n",
    "2. Start with the basics: Familiarize yourself with the basic programming concepts such as variables, data types and control structures.\n",
    "\n",
    "3. Practice, practice, practice: The best way to learn programming is through hands-on experience\\\n",
    "\"\"\" \n",
    ")\n",
    "\n",
    "response = chat_prompt_template.format_prompt(\n",
    "    conversation=[human_message, ai_message],\n",
    "    word_count=\"10\"\n",
    ").to_messages()\n",
    "\n",
    "print(f\"{type(response)}\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# message placeholders\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you are a helpful assistant\"),\n",
    "    MessagesPlaceholder(\"msgs\")\n",
    "    # (\"placeholder\", \"{msgs}\")\n",
    "])\n",
    "\n",
    "input = chat_prompt_template.invoke({\"msgs\": [HumanMessage(content=\"Hello there!\")]})\n",
    "\n",
    "input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-langchain-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
