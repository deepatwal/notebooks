{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_ollama import OllamaLLM, ChatOllama, OllamaEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "import psycopg\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON, POST\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langain & Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check ollama status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl --location 'http://127.0.0.1:11434/api/generate' \\\n",
    "# --header 'Content-Type: application/json' \\\n",
    "# --data '{ \\\n",
    "#     \"model\": \"llama3.2:3b\", \\\n",
    "#     \"prompt\": \"hello llama!\",  \\\n",
    "#     \"options\": { \\\n",
    "#         \"temperature\": 0 \\\n",
    "#     } \\\n",
    "# }' \\\n",
    "# | python -m json.tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl http://localhost:11434/api/tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ollama model: configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OllamaLLM(model='llama3.2:3b', temperature=0.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OllamaLLM(model=\"llama3.2:3b\", temperature=0)\n",
    "# llm = OllamaLLM(model=\"deepseek-r1:8b\", temperature=0)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOllama(model='llama3.2:3b', temperature=0.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_ollama = ChatOllama(model=\"llama3.2:3b\", temperature=0)\n",
    "chat_ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing llm: invoke\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\n"
     ]
    }
   ],
   "source": [
    "# llm.invoke(input=\"tell me a joke\")\n",
    "response = llm.invoke(\"hello ollama!\")\n",
    "\n",
    "# response = llm.invoke(\"Create an agent that uses Ollama function calling in Langchain.\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Je aime programmer.', additional_kwargs={}, response_metadata={'model': 'llama3.2:3b', 'created_at': '2025-04-14T19:07:45.0711592Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2673019600, 'load_duration': 2457519600, 'prompt_eval_count': 42, 'prompt_eval_duration': 153058000, 'eval_count': 5, 'eval_duration': 57947000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-87d0096c-961f-4def-8049-07069bb59937-0', usage_metadata={'input_tokens': 42, 'output_tokens': 5, 'total_tokens': 47})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are a helpful translator. Translate the user sentence to French.\"),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "chat_ollama.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing llm: chat prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I'm trying to figure out how LangSmith can help with testing. I remember that LangSmith is some kind of AI tool related to language processing, maybe for writing or something like that. But I'm not exactly sure about its specific features beyond generating text.\n",
      "\n",
      "The user mentioned testing in their question, so I guess they're asking if LangSmith has any features that assist in testing processes. Testing can be a broad term—like software testing, quality assurance, user acceptance testing, etc.—so I need to think about how an AI tool like LangSmith might fit into these contexts.\n",
      "\n",
      "First, maybe LangSmith can help with automated testing. If it's capable of generating text based on inputs, perhaps it can create test cases or scenarios automatically. That would save time compared to manual testing. But I'm not sure if LangSmith has that feature or not.\n",
      "\n",
      "Another angle is using LangSmith for functional testing. If you're testing a system's functionality, maybe LangSmith can simulate user interactions or generate expected outputs, helping to verify if the system behaves as intended. For example, if you have a chatbot, LangSmith could be used to test its responses by generating various inputs and checking if the outputs meet expectations.\n",
      "\n",
      "Then there's integration testing. If LangSmith can interact with other systems or APIs, it might help in testing how different components work together. But again, I'm not certain about LangSmith's capabilities in that area.\n",
      "\n",
      "Testing for natural language processing models could also be a use case. Maybe LangSmith can generate test cases or examples to evaluate the performance of NLP systems. This would involve creating scenarios where the system should perform well and then checking if it does.\n",
      "\n",
      "I also wonder about testing in the context of localization—ensuring that software works correctly in different languages. LangSmith might help by generating localized text for testing purposes, ensuring that translations are accurate and consistent.\n",
      "\n",
      "Another thought is about performance testing. If LangSmith can simulate multiple users or requests, it could help stress-test a system to see how it handles high loads. This would be useful for scalability testing.\n",
      "\n",
      "Documentation testing is another possibility. If LangSmith can generate documentation, maybe it can also test that documentation by checking for accuracy and completeness. But I'm not sure if that's a feature it offers.\n",
      "\n",
      "I should also consider the user interface aspects of testing. Maybe LangSmith can assist in testing how an application presents information to users, ensuring usability and accessibility.\n",
      "\n",
      "Wait, but I might be mixing up different tools here. I know about some AI tools that help with code testing or static analysis, but Langsmith seems more focused on text generation. So perhaps its role is more in generating test scripts or scenarios rather than executing them.\n",
      "\n",
      "In any case, the key points would likely involve using LangSmith to automate parts of the testing process, generate test cases, simulate user interactions, and possibly integrate with other testing frameworks. It might also help in validating outputs against expected results, especially for text-based systems.\n",
      "\n",
      "I should structure this into clear sections, maybe like automated testing, functional testing, integration testing, NLP model testing, localization testing, performance testing, documentation testing, and UI/UX testing. Each section would explain how LangSmith could assist in that specific area.\n",
      "\n",
      "But I'm not entirely sure about all these points, so I might need to check if LangSmith actually has these features or if they're more theoretical possibilities based on its general capabilities as a language processing tool.\n",
      "</think>\n",
      "\n",
      "LangSmith can be effectively utilized across various testing scenarios through its text generation and processing capabilities. Here's how it can assist:\n",
      "\n",
      "1. **Automated Testing**: LangSmith can generate test cases automatically, reducing manual effort and enhancing efficiency in creating scenarios for testing.\n",
      "\n",
      "2. **Functional Testing**: It can simulate user interactions by generating inputs and expected outputs, helping to verify system functionality, especially useful for chatbots or interactive systems.\n",
      "\n",
      "3. **Integration Testing**: If capable of interacting with other systems or APIs, LangSmith could assist in testing component interactions, ensuring seamless integration.\n",
      "\n",
      "4. **NLP Model Testing**: LangSmith can generate test cases to evaluate NLP models, checking their performance against expected outputs.\n",
      "\n",
      "5. **Localization Testing**: It can aid in generating localized text for testing, ensuring accuracy and consistency across different languages.\n",
      "\n",
      "6. **Performance Testing**: By simulating multiple users or requests, LangSmith can help stress-test systems to assess scalability under high loads.\n",
      "\n",
      "7. **Documentation Testing**: While not explicitly stated, LangSmith might assist in generating and testing documentation for accuracy and completeness.\n",
      "\n",
      "8. **UI/UX Testing**: It could evaluate how information is presented to users, ensuring usability and accessibility.\n",
      "\n",
      "In summary, LangSmith's role in testing likely involves automating test generation, simulating interactions, and validating outputs across various system types, enhancing efficiency and effectiveness in the testing process.\n"
     ]
    }
   ],
   "source": [
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "]) \n",
    "\n",
    "chain = chat_prompt_template | llm\n",
    "\n",
    "response = chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing llm: chat prompt template & StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I'm trying to figure out how LangSmith can help with testing. I remember that LangSmith is some kind of AI tool related to language processing, maybe for writing or something like that. But I'm not exactly sure about its features beyond generating text.\n",
      "\n",
      "The user mentioned testing in their question, so I guess they're asking if LangSmith can be used for testing purposes. Hmm, how does that work? Well, testing usually involves checking if a system works as expected, right? So maybe LangSmith can help test other AI systems or applications?\n",
      "\n",
      "Wait, but LangSmith is more about generating text. Maybe it's used to create test cases or scenarios for testing something else. Or perhaps it can simulate user interactions to see how well another system responds. That could be useful for testing chatbots or other language-based applications.\n",
      "\n",
      "Another thought: maybe LangSmith can help in automating tests. Like, if you have a lot of test cases, LangSmith could generate the necessary inputs or expected outputs automatically. Or perhaps it can analyze the results of tests to find bugs or issues in the system under test.\n",
      "\n",
      "I'm also thinking about how LangSmith might assist in testing its own capabilities. For example, if someone is developing an AI model, they might use LangSmith to create varied inputs and see how well their model performs. That could help in identifying weaknesses or areas for improvement.\n",
      "\n",
      "But I'm not entirely sure if LangSmith has specific features built for testing. It might just be that it's a versatile tool that can be adapted for testing purposes by generating test data, simulating user interactions, or automating repetitive test scenarios.\n",
      "\n",
      "I should also consider the possible limitations. Maybe LangSmith isn't designed specifically as a testing tool, so its capabilities in this area might be limited compared to dedicated testing tools. But it could still offer some helpful functionalities for certain aspects of testing.\n",
      "\n",
      "Overall, I think LangSmith can help with testing by providing generated text for test cases, simulating user interactions, or automating parts of the testing process. It's probably most useful in scenarios where generating varied inputs or expected outputs is needed to test a system effectively.\n",
      "</think>\n",
      "\n",
      "LangSmith can assist with testing in several ways:\n",
      "\n",
      "1. **Test Case Generation**: It can generate diverse and complex text inputs for testing systems, helping to create varied scenarios for evaluation.\n",
      "\n",
      "2. **Simulation of User Interactions**: By producing realistic conversations or interactions, LangSmith can simulate user behavior, aiding in the testing of chatbots or language-based applications.\n",
      "\n",
      "3. **Automated Testing Processes**: It may help automate repetitive tasks in testing, such as creating test scripts or analyzing results, though this might be more indirect compared to dedicated tools.\n",
      "\n",
      "4. **Internal Testing Capabilities**: Developers can use LangSmith to test their own AI models by generating inputs and assessing performance, aiding in the identification of weaknesses.\n",
      "\n",
      "While not a dedicated testing tool, LangSmith's text generation capabilities make it adaptable for various testing needs, particularly where generating test data or simulating interactions is beneficial.\n"
     ]
    }
   ],
   "source": [
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "]) \n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = chat_prompt_template | llm | output_parser\n",
    "\n",
    "response = chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create vector store & a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_store_retriever: tags=['FAISS', 'OllamaEmbeddings'] vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000233810D3DD0> search_kwargs={}\n"
     ]
    }
   ],
   "source": [
    "# 1. select a specfic datasource. In this case a web page. \n",
    "# 2. save extracted content from the web page as docs.\n",
    "# 3. index the docs using FAISS vector store.\n",
    "# 4. convert the vector store to retriever.\n",
    "\n",
    "web_base_loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "\n",
    "docs = web_base_loader.load()\n",
    "\n",
    "# print(f\"type(docs) : {type(docs)} \\n\")\n",
    "# print(f\"len(docs) : {len(docs)}\\n\")\n",
    "# print(f\"docs: {docs} \\n\")\n",
    "# type(f\"docs[0] : {docs[0]} \\n\")\n",
    "# print(f\"docs[0].page_content : {docs[0].page_content} \\n\")\n",
    "\n",
    "recursive_character_text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = recursive_character_text_splitter.split_documents(documents=docs)\n",
    "\n",
    "\n",
    "# print(type(documents))\n",
    "# print(len(documents))\n",
    "# print(documents)\n",
    "# print(documents[0])\n",
    "# print(documents[2])\n",
    "\n",
    "ollama_embedding = OllamaEmbeddings(model=\"llama3.2:3b\")\n",
    "vector_store = FAISS.from_documents(documents=documents, embedding=ollama_embedding)\n",
    "\n",
    "\n",
    "# print(f\"vector_store.index.ntotal: {vector_store.index.ntotal}\")\n",
    "# print(f\"vector_store._get_retriever_tags() : {vector_store._get_retriever_tags()}\")\n",
    "# print(f\"vector_store.index_to_docstore_id : {vector_store.index_to_docstore_id}\") \n",
    "# print(f\"type(vector_store.index_to_docstore_id) : {type(vector_store.index_to_docstore_id)}\") \n",
    "\n",
    "vector_store_retriever = vector_store.as_retriever()\n",
    "print(f\"vector_store_retriever: {vector_store_retriever}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## document chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no information provided in the context about LangSmith's capabilities or features related to testing. The text only mentions that LangSmith is a project or organization (indicated by the \"LangSmith SDK\" and \"LangChain Python Docs\" links), but it does not provide any details on how it can be used for testing.\n"
     ]
    }
   ],
   "source": [
    "# 5. create a chat prompt template\n",
    "# 6. create a stuff document chain that accepts a llm model and chat prompt template & we can also run stuff document chain by passing in documents directly\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_template(\n",
    "\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\"\n",
    ")\n",
    "\n",
    "documents_chain = create_stuff_documents_chain(llm=llm, prompt=chat_prompt_template)\n",
    "response = documents_chain.invoke(\n",
    "    {\n",
    "        \"input\": \"how can langsmith help with testing?\",\n",
    "        \"context\": documents        \n",
    "    }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retrieval chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'answer': 'There is no information provided in the context about '\n",
      "              \"LangSmith's capabilities or features related to testing. The \"\n",
      "              'text only mentions that LangSmith is a project or organization '\n",
      "              '(indicated by the \"LangSmith SDK\" and \"LangChain Python Docs\" '\n",
      "              'links), but it does not provide any details on how it can be '\n",
      "              'used for testing.',\n",
      "    'context': [   Document(metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': '🦜️🛠️ LangSmith', 'language': 'en'}, page_content='🦜️🛠️ LangSmith\\n\\n\\n\\n\\n\\n\\nSkip to main contentJoin us at  Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppPage Not FoundWe could not find what you were looking for.Head back to our main docs page or use the search bar to find the page you need.CommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2025 LangChain, Inc.')],\n",
      "    'input': 'how can langsmith help with testing?'}\n"
     ]
    }
   ],
   "source": [
    "# 7. create a document retrieval chain that takes vector store retriever and stuff document chain\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(vector_store_retriever, documents_chain) \n",
    "response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "\n",
    "# print(type(response))\n",
    "pprint.pprint(response, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conversation retrieval chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    (\"user\", \"Given the above conversation, generate a search query to look up to get information relevant to the conversation\")\n",
    "])\n",
    "\n",
    "history_aware_retriever_chain = create_history_aware_retriever(llm, vector_store_retriever, chat_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': \"We'd be happy to help you test your Large Language Model (LLM) \"\n",
      "           'applications. Here are some ways we can assist:\\n'\n",
      "           '\\n'\n",
      "           '1. **Conversational Testing**: We can engage in conversations with '\n",
      "           'your LLM, providing it with a variety of prompts and scenarios to '\n",
      "           'test its understanding, accuracy, and response quality.\\n'\n",
      "           '2. **Error Identification**: Our team can help identify errors or '\n",
      "           \"biases in your LLM's responses, such as incorrect information, \"\n",
      "           'inconsistencies, or inappropriate content.\\n'\n",
      "           '3. **Performance Evaluation**: We can evaluate the performance of '\n",
      "           'your LLM on specific tasks, such as answering questions, '\n",
      "           'generating text, or completing tasks.\\n'\n",
      "           '4. **Data Quality Assessment**: We can assess the quality and '\n",
      "           \"relevance of the data used to train your LLM, ensuring it's \"\n",
      "           'accurate, diverse, and up-to-date.\\n'\n",
      "           '\\n'\n",
      "           'To get started, please provide more details about your LLM '\n",
      "           'application, such as:\\n'\n",
      "           '\\n'\n",
      "           '* What specific tasks or domains does it focus on?\\n'\n",
      "           '* What are your goals for testing and improving the model?\\n'\n",
      "           \"* Do you have any existing test data or scenarios you'd like us to \"\n",
      "           'use?\\n'\n",
      "           '\\n'\n",
      "           \"We'll work with you to create a customized testing plan that meets \"\n",
      "           'your needs.',\n",
      " 'chat_history': [HumanMessage(content='Can LangSmith help test my LLM applications?', additional_kwargs={}, response_metadata={}),\n",
      "                  AIMessage(content='Yes!', additional_kwargs={}, response_metadata={})],\n",
      " 'context': [Document(metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': '🦜️🛠️ LangSmith', 'language': 'en'}, page_content='🦜️🛠️ LangSmith\\n\\n\\n\\n\\n\\n\\nSkip to main contentJoin us at  Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppPage Not FoundWe could not find what you were looking for.Head back to our main docs page or use the search bar to find the page you need.CommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2025 LangChain, Inc.')],\n",
      " 'input': 'tell me how'}\n"
     ]
    }
   ],
   "source": [
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the user's questions based on the below context:\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, chat_prompt_template)\n",
    "retrieval_chain = create_retrieval_chain(history_aware_retriever_chain, document_chain)\n",
    "\n",
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "\n",
    "response = retrieval_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"tell me how\"\n",
    "})\n",
    "\n",
    "pprint.pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama_embedding = OllamaEmbeddings(model=\"mxbai-embed-large:335m\")\n",
    "# ollama_embedding = OllamaEmbeddings(model=\"nomic-embed-text:latest\")\n",
    "ollama_embedding = OllamaEmbeddings(model=\"bge-m3:567m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### connect to pgvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format: postgresql+psycopg2://user:password@host:port/dbname\n",
    "# Database Connection Details\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "\n",
    "CONNECTION_STRING = f\"postgresql+psycopg://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "COLLECTION_NAME = \"dbpedia_docs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connecting to PGVector 'dbpedia_docs'...\n",
      "connection successfull!\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nConnecting to PGVector '{COLLECTION_NAME}'...\")\n",
    "try:\n",
    "    # If the collection table doesn't exist, PGVector will try to create it.\n",
    "    vectorstore = PGVector(\n",
    "        connection=CONNECTION_STRING,\n",
    "        embeddings=ollama_embedding,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        use_jsonb=True\n",
    "        # pre_delete_collection=True\n",
    "        # Use pre_delete_collection=True if you want to clear the collection on every run (USE WITH CAUTION!)\n",
    "        # pre_delete_collection=False,\n",
    "    )\n",
    "    print(f\"connection successfull!\")\n",
    "except psycopg.OperationalError as e:\n",
    "    print(f\"\\nDatabase Connection Error: {e}\")\n",
    "    exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during PGVector connection: {e}\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### connect to ontotext graph db and fetch all the entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPHDB_BASE_URL = os.getenv(\"GRAPHDB_BASE_URL\")\n",
    "GRAPHDB_REPOSITORY = os.getenv(\"GRAPHDB_REPOSITORY\")\n",
    "\n",
    "# Format: {base_url}/repositories/{repository_id}\n",
    "SPARQL_ENDPOINT = urljoin(GRAPHDB_BASE_URL.strip('/') + '/', f\"repositories/{GRAPHDB_REPOSITORY}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = r\"\"\"\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "\n",
    "SELECT ?class\n",
    "FROM <http://dbpedia.org/model>\n",
    "WHERE {\n",
    "  ?class a owl:Class .\n",
    "  FILTER (\n",
    "    regex(STRAFTER(STR(?class), \"http://dbpedia.org/ontology/\"), \"^[\\\\x00-\\\\x7F]+$\")\n",
    "  )\n",
    "}\n",
    "\"\"\"\n",
    "sparql = SPARQLWrapper(SPARQL_ENDPOINT)\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "entitiies = []\n",
    "\n",
    "try:\n",
    "    sparql.setQuery(query)\n",
    "    results = sparql.query().convert()\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        entitiies.append(result[\"class\"][\"value\"])\n",
    "        # print(result[\"class\"][\"value\"])\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639,\n",
       " ['http://dbpedia.org/ontology/AcademicConference',\n",
       "  'http://dbpedia.org/ontology/AcademicJournal'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entitiies), entitiies[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-ollama-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
